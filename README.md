# Vision-Transformer-Collection
Variants of Vision Transformer and its downstream tasks

## Backbone
* Vision Transformer [paper](https://arxiv.org/abs/2010.11929) [code](https://github.com/google-research/vision_transformer)
* Swin Transformer [paper](https://arxiv.org/abs/2103.14030) [code](https://github.com/microsoft/Swin-Transformer)
* DVT [paper](https://arxiv.org/abs/2105.15075) [code](https://github.com/blackfeather-wang/Dynamic-Vision-Transformer)
* PVT [paper](https://arxiv.org/abs/2102.12122) [code](https://github.com/whai362/PVT)
* Twins [paper](https://arxiv.org/abs/2104.13840) [code](https://github.com/Meituan-AutoML/Twins)
* TNT [paper](https://arxiv.org/abs/2103.00112) [code](https://github.com/lucidrains/transformer-in-transformer)
* Mobile-ViT [paper](https://arxiv.org/abs/2110.02178?context=cs.LG) [code](https://github.com/chinhsuanwu/mobilevit-pytorch)
* BoTNet [paper](https://arxiv.org/abs/2101.11605)

## Transfer Learning
* Pre-Trained Image Processing Transformer [paper]{https://arxiv.org/abs/2012.00364} [code]{https://github.com/huawei-noah/Pretrained-IPT}


## Fusion
* Multi-Modal Fusion Transformer for End-to-End Autonomous Driving [paper](https://arxiv.org/abs/2104.09224)

## Tracking
* Transformer Tracking [paper](https://arxiv.org/abs/2103.15436) [code]{https://github.com/chenxin-dlut/TransT}

## Explainable
* Development and testing of an image transformer for explainable autonomous driving systems [paper]{https://arxiv.org/abs/2110.05559}
